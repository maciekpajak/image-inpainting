{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsaI5Si3J8Mz"
   },
   "source": [
    "Install additional packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32403,
     "status": "ok",
     "timestamp": 1675256961038,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "7NZC0xFrZlsG",
    "outputId": "7313fe28-93a2-4d2a-adf4-93447042c16a"
   },
   "outputs": [],
   "source": [
    "# To generate GIFs\n",
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcfmW4ddKGZ4"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lWtAMGKZnFU"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7WWAa2xKK80"
   },
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lZOP1KYNy2-"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uo_PcS9H7vv"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE=(32,32,3)\n",
    "BLOCK_SIZE = (16, 16)\n",
    "BLOCK_SHAPE =(16,16,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPES6UVEKNqG"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a106h7bwKpwG"
   },
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24806,
     "status": "ok",
     "timestamp": 1675256989615,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "KnrdIKwpaBBD",
    "outputId": "8818cc67-3ed5-45a9-ea53-4975442aa2c6"
   },
   "outputs": [],
   "source": [
    "(y_train, _), (y_test,_) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "y_train = (y_train ) / 255.  # Normalize the images to [0, 1]\n",
    "y_test = (y_test ) / 255.  # Normalize the images to [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXSrTmF9KsGz"
   },
   "source": [
    "cutout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W02-dpe2gLuR"
   },
   "outputs": [],
   "source": [
    "x_train = tf.identity(y_train)\n",
    "x_test = tf.identity(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BKYMLS-PTyF"
   },
   "outputs": [],
   "source": [
    "class RandomCutout():\n",
    "  def __init__(self, mask_size=(16,16), border=(0,0), name = 'random_cutout', **kwargs):\n",
    "    super(RandomCutout, self).__init__(**kwargs)\n",
    "    \n",
    "    self.mask_size = mask_size\n",
    "    self.border = border\n",
    "\n",
    "  def __call__(self, image_batch):\n",
    "      x = tf.shape(image_batch)[1]\n",
    "      y = tf.shape(image_batch)[2]\n",
    "\n",
    "      xoffset = tf.cast(tf.math.ceil(self.mask_size[0] / 2.) + self.border[0], dtype=tf.int32)\n",
    "      yoffset = tf.cast(tf.math.ceil(self.mask_size[1] / 2.) + self.border[1], dtype=tf.int32)\n",
    "      xmin, xmax = xoffset, x - xoffset\n",
    "      ymin, ymax = yoffset, y - yoffset\n",
    "\n",
    "      if xmin < xmax:\n",
    "        xoffset = tf.random.uniform(shape=[], minval=xmin, maxval=xmax, dtype=tf.dtypes.int32)\n",
    "      else:\n",
    "        xoffset = tf.cast(x / 2, dtype=tf.int32)\n",
    "      if ymin < ymax:\n",
    "        yoffset = tf.random.uniform(shape=[], minval=ymin, maxval=ymax, dtype=tf.dtypes.int32)\n",
    "      else:\n",
    "        yoffset = tf.cast(y / 2, dtype=tf.int32)\n",
    "\n",
    "      xmin, xmax = xoffset - tf.cast(tf.math.ceil(self.mask_size[0] / 2.), dtype=tf.int32), xoffset + tf.cast(tf.math.ceil(self.mask_size[0] / 2.), dtype=tf.int32)\n",
    "      ymin, ymax = yoffset - tf.cast(tf.math.ceil(self.mask_size[1] / 2.), dtype=tf.int32), yoffset + tf.cast(tf.math.ceil(self.mask_size[1] / 2.), dtype=tf.int32)\n",
    "\n",
    "      mask = tfa.image.cutout(tf.zeros_like(image_batch), mask_size=self.mask_size, offset=(yoffset,xoffset), constant_values=1.)\n",
    "      context = image_batch * (1 - mask)\n",
    "      random_block = image_batch * mask\n",
    "      return context, random_block, mask, (ymin, xmin, ymax-ymin, xmax-xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQTjsoBYD7OX"
   },
   "outputs": [],
   "source": [
    "random_cutout = RandomCutout(mask_size=BLOCK_SIZE, border=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2Kx6sjMK3jA"
   },
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pij7VjPBK7jF"
   },
   "source": [
    "## generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1675257969823,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "I1emGH3maNZx",
    "outputId": "de56b31b-95cc-4fdb-f33e-1607c36e3c78"
   },
   "outputs": [],
   "source": [
    "def Generator(input_shape=(32,32,3)):\n",
    "    \n",
    "    # generator architecture\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Generator\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOJyelndLBGg"
   },
   "source": [
    "## discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1675259445959,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "ToljRD27aWUF",
    "outputId": "f18663b7-dc29-46dc-aae1-97f41c5017c5"
   },
   "outputs": [],
   "source": [
    "def Discriminator(input_shape=(16,16,3)):\n",
    "    \n",
    "    # discriminator architecture\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Discriminator\")\n",
    "    return model\n",
    "\n",
    "discriminator = Discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mxlPPYFLRxn"
   },
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1675258026192,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "nktOOEF9NgAM",
    "outputId": "57c7ba95-d16c-44e4-c33f-8fa408f4fc58"
   },
   "outputs": [],
   "source": [
    "class psnr_metric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name = 'psnr', **kwargs):\n",
    "        super(psnr_metric, self).__init__(**kwargs)\n",
    "        self.value = self.add_weight('value', initializer = 'zeros')\n",
    "        self.count = self.add_weight('count', initializer = 'zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred,sample_weight=None):\n",
    "        self.value.assign_add(tf.reduce_mean(tf.image.psnr(y_true, y_pred, 2)))\n",
    "        self.count.assign_add(1)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.value.assign(0)\n",
    "        self.count.assign(0)\n",
    "\n",
    "    def result(self):\n",
    "        return self.value / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675258028593,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "P4QR0ifMWU7L",
    "outputId": "7597574b-a191-4c4a-ad4d-c07ffe32b7ee"
   },
   "outputs": [],
   "source": [
    "class ssim_metric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name = 'ssim', **kwargs):\n",
    "        super(ssim_metric, self).__init__(**kwargs)\n",
    "        self.value = self.add_weight('value', initializer = 'zeros')\n",
    "        self.count = self.add_weight('count', initializer = 'zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred,sample_weight=None):\n",
    "        self.value.assign_add(tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2)))\n",
    "        self.count.assign_add(1)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.value.assign(0)\n",
    "        self.count.assign(0)\n",
    "\n",
    "    def result(self):\n",
    "        return self.value / self.count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQMslQBwLGzj"
   },
   "source": [
    "# Context encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRQZgcFZFweB"
   },
   "outputs": [],
   "source": [
    "class ContextEncoder(tf.keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "    def __init__(self, \n",
    "                  discriminator,\n",
    "                  generator,\n",
    "                  generator_extra_steps=1,\n",
    "                  discriminator_extra_steps=1,\n",
    "                  mask_size=(16,16),\n",
    "                  border=(2,2),\n",
    "                  name=\"context_encoder\"):\n",
    "      super(ContextEncoder, self).__init__()\n",
    "\n",
    "      self.discriminator = discriminator\n",
    "      self.generator = generator\n",
    "\n",
    "      self.d_steps = discriminator_extra_steps\n",
    "      self.g_steps = generator_extra_steps\n",
    "\n",
    "      self.psnr_metric = psnr_metric(name=\"psnr\")\n",
    "      self.ssim_metric = ssim_metric(name=\"ssim\")\n",
    "\n",
    "      self.mask_size = mask_size\n",
    "      self.border = border\n",
    "\n",
    "\n",
    "    def compile(self, generator_optimizer, discriminator_optimizer, discriminator_loss, adversarial_loss, reconstruction_loss, lam=0.99):\n",
    "      super(ContextEncoder, self).compile()\n",
    "      self.generator_optimizer = generator_optimizer\n",
    "      self.discriminator_optimizer = discriminator_optimizer\n",
    "      self.adversarial_loss = adversarial_loss\n",
    "      self.reconstruction_loss = reconstruction_loss\n",
    "      self.discriminator_loss = discriminator_loss\n",
    "      self.lam = lam\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        # metrics = super().metrics\n",
    "        # metrics.append(self.psnr_metric)\n",
    "        return [self.psnr_metric, self.ssim_metric]\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "      if isinstance(data, tuple):\n",
    "            x_batch = data[0]\n",
    "            y_batch = data[1]\n",
    "\n",
    "      context, random_region, mask, coords = random_cutout(x_batch)\n",
    "      context_white = context + mask\n",
    "      real_images = y_batch\n",
    "\n",
    "      # Generate fake images from the latent vector\n",
    "      generated = self.generator(context_white, training=False)\n",
    "      fake_images = context + generated * mask\n",
    "\n",
    "      fake_block = tf.image.crop_to_bounding_box(fake_images, *coords)\n",
    "      real_block = tf.image.crop_to_bounding_box(real_images, *coords)\n",
    "      # Get the logits for the fake images\n",
    "      fake_logits = self.discriminator(fake_block, training=False)\n",
    "      # Get the logits for the real images\n",
    "      real_logits = self.discriminator(real_block, training=False)\n",
    "\n",
    "      # Calculate loss\n",
    "      d_loss = self.discriminator_loss(real_logits, fake_logits)\n",
    "      g_loss = self.lam * self.reconstruction_loss(real_block, fake_block) + (1-self.lam) * self.adversarial_loss(fake_logits)\n",
    "\n",
    "      self.psnr_metric.update_state(real_images,fake_images)\n",
    "      self.ssim_metric.update_state(real_images,fake_images)\n",
    "      return {\"g_loss\": g_loss,\"d_loss\": d_loss, \"psnr\": self.psnr_metric.result(), \"ssim\": self.ssim_metric.result()}\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "      if isinstance(data, tuple):\n",
    "            x_batch = data[0]\n",
    "            y_batch = data[1]\n",
    "\n",
    "      context, random_region,mask, coords = random_cutout(x_batch)\n",
    "      context_white = context + mask\n",
    "      real_images = y_batch\n",
    "\n",
    "      \n",
    "      for i in range(self.d_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "          # Generate fake images from the latent vector\n",
    "          generated = self.generator(context_white, training=True)\n",
    "          fake_images = context + generated * mask\n",
    "\n",
    "          fake_block = tf.image.crop_to_bounding_box(fake_images, *coords)\n",
    "          real_block = tf.image.crop_to_bounding_box(real_images, *coords)\n",
    "          # Get the logits for the fake images\n",
    "          fake_logits = self.discriminator(fake_block, training=True)\n",
    "          # Get the logits for the real images\n",
    "          real_logits = self.discriminator(real_block, training=True)\n",
    "\n",
    "          # Calculate loss\n",
    "          d_loss = self.discriminator_loss(real_logits, fake_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the discriminator loss\n",
    "        d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        # Update the weights of the discriminator using the discriminator optimizer\n",
    "        self.discriminator_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
    "\n",
    "      for i in range(self.g_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "          # Generate fake images using the generator\n",
    "          generated = self.generator(context_white, training=True)\n",
    "          fake_images = context + generated * mask\n",
    "          fake_block = tf.image.crop_to_bounding_box(fake_images, *coords)\n",
    "          real_block = tf.image.crop_to_bounding_box(real_images, *coords)\n",
    "          # Get the discriminator logits for fake images\n",
    "          gen_img_logits = self.discriminator(fake_block, training=True)\n",
    "          # Calculate the generator loss\n",
    "          g_loss = self.lam * self.reconstruction_loss(real_block, fake_block) + (1-self.lam) * self.adversarial_loss(fake_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.generator_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n",
    "\n",
    "      # Compute our own metrics\n",
    "      self.psnr_metric.update_state(real_images,fake_images)\n",
    "      self.ssim_metric.update_state(real_images,fake_images)\n",
    "      return {\"g_loss\": g_loss,\"d_loss\": d_loss, \"psnr\": self.psnr_metric.result(), \"ssim\": self.ssim_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTbSii0fc8z4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq439CDHLMUL"
   },
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0Z9yvXgLfVy"
   },
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYDY9eLQdEKK"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mae = tf.keras.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1675258536511,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "M3THkRildEKP",
    "outputId": "c5918527-3e90-4266-a468-e4b9e941f420"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_preds, fake_preds):\n",
    "  real_loss = cross_entropy(tf.ones_like(real_preds), real_preds)\n",
    "  fake_loss = cross_entropy(tf.zeros_like(fake_preds), fake_preds)\n",
    "  total_loss = real_loss + fake_loss\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1675258542875,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "3faJ5SVIdEKV",
    "outputId": "7d75dd96-cbd8-4603-f780-d67d4ade4d3a"
   },
   "outputs": [],
   "source": [
    "def adv_loss(fake_preds):\n",
    "  return cross_entropy(tf.ones_like(fake_preds), fake_preds)\n",
    "\n",
    "def rec_loss(y_true, y_pred):\n",
    "  return mse(y_true, y_pred)     # MSE / L2\n",
    "  # return mae(y_true, y_pred)  # MAE / L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aro7bW6ILrA0"
   },
   "source": [
    "## optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNf0_7oIdEKf"
   },
   "outputs": [],
   "source": [
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9)          \n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-7, beta_1=0.9)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQU2-g3mLvER"
   },
   "source": [
    "## model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xuyYdIwc83U"
   },
   "outputs": [],
   "source": [
    "MASK_SIZE = (16,16)\n",
    "BORDER = (2,2)\n",
    "ctxtenc = ContextEncoder(discriminator=Discriminator(), \n",
    "                         generator= Generator(),\n",
    "                         mask_size=MASK_SIZE,\n",
    "                         border=BORDER)\n",
    "\n",
    "ctxtenc.compile(\n",
    "    generator_optimizer=generator_optimizer,\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    discriminator_loss=discriminator_loss,\n",
    "    adversarial_loss = adv_loss,\n",
    "    reconstruction_loss=rec_loss,\n",
    "    lam = 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCNmkfBZLWET"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 2752,
     "status": "ok",
     "timestamp": 1675262582644,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "ALYf2NkOrjoj",
    "outputId": "223e2ebb-8710-41f7-a427-b836e9bf8514"
   },
   "outputs": [],
   "source": [
    "images_to_show = x_test[:25]\n",
    "context, random_block, mask, coords = RandomCutout(mask_size=(16,16),border=(8,8))(test_batch)\n",
    "fig = plt.figure()\n",
    "plt.suptitle(\"Input\", fontsize=14)\n",
    "for i, img in enumerate(context+mask):\n",
    "    plt.subplot(5,5 ,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.savefig('image_at_epoch_0000.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1675265241008,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "s21VU90jiCzm",
    "outputId": "9c427ae6-4271-4ce0-e507-03658ef1ff0b"
   },
   "outputs": [],
   "source": [
    "class GANMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, images_to_show=None, save_every=1,mask_size=(16,16),border=(8,8)):\n",
    "        self.images_to_show = images_to_show\n",
    "        self.save_every = save_every\n",
    "        self.random_cutout = RandomCutout(mask_size, border)\n",
    "        print(self.images_to_show.shape)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "      if (epoch + 1) % self.save_every == 0:\n",
    "        \n",
    "        context, random_region, mask, coords = self.random_cutout(self.images_to_show)\n",
    "        \n",
    "        context_white = context + mask\n",
    "        generated = self.model.generator(context_white, training=False)\n",
    "\n",
    "        reconstructed_images = context + generated * mask\n",
    "\n",
    "        plt.ioff()\n",
    "        fig = plt.figure()\n",
    "        plt.suptitle(f\"epoch:{epoch+1}\")\n",
    "        for i in range(reconstructed_images.shape[0]):\n",
    "            plt.subplot(5,5, i+1)\n",
    "            plt.imshow(reconstructed_images[i])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch+1))\n",
    "        plt.close(fig)\n",
    "\n",
    "show_images = GANMonitor(images_to_show=images_to_show, save_every=1, mask_size=(16,16), border=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKdT1wnNkdna"
   },
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.discriminator_optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.discriminator_optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.discriminator_optimizer.lr, scheduled_lr)\n",
    "        if scheduled_lr != lr:\n",
    "          print(\"\\nEpoch %d: Learning rate is %6.4f.\" % (epoch+1, scheduled_lr))\n",
    "\n",
    "LR_SCHEDULE = [\n",
    "    # (epoch to start, learning rate) tuples\n",
    "    (30, 1e-5),\n",
    "]\n",
    "\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr\n",
    "\n",
    "scheduler = CustomLearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1072151,
     "status": "error",
     "timestamp": 1675268280622,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "lfuL2-OXc87M",
    "outputId": "8a345f72-c758-42de-eacc-1f034ea27e31"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "history = ctxtenc.fit(x=x_train,\n",
    "                      y=y_train,\n",
    "                      validation_data=(x_test, y_test),\n",
    "                      epochs=EPOCHS, \n",
    "                      initial_epoch = 0,\n",
    "                      batch_size = BATCH_SIZE,\n",
    "                      shuffle=True, \n",
    "                      callbacks=[show_images, scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZSwnnIZLz7e"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 2551,
     "status": "ok",
     "timestamp": 1675267105303,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "2FBph-R24vYk",
    "outputId": "103e5c35-5036-4a73-fbcf-5a3741252187"
   },
   "outputs": [],
   "source": [
    "test_batch = y_test[:25]\n",
    "context, random_block, mask, coords = random_cutout(test_batch)\n",
    "context_white = context + mask\n",
    "reconstructed = context + ctxtenc.generator(context_white, training=False)*mask\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.suptitle(\"Output\", fontsize=14)\n",
    "for i, img in enumerate(reconstructed):\n",
    "    plt.subplot(5,5 ,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQDdsT2nL_jY"
   },
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLih01nXodu9"
   },
   "outputs": [],
   "source": [
    "## Plot train and validation curves\n",
    "g_loss = history.history['g_loss']\n",
    "val_g_loss =  history.history['val_g_loss']\n",
    "\n",
    "d_loss =  history.history['d_loss']\n",
    "val_d_loss =  history.history['val_d_loss']\n",
    "\n",
    "psnr =  history.history['psnr']\n",
    "val_psnr =  history.history['val_psnr']\n",
    "\n",
    "ssim =  history.history['ssim']\n",
    "val_ssim =  history.history['val_ssim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1675267105309,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "LznQBrj5odu-",
    "outputId": "05a536ac-4a88-4395-9a4b-2b88e55d90a3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(g_loss, label='g_loss')\n",
    "plt.plot(val_g_loss, label='val_g_loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0,.1])\n",
    "plt.title('Training and Validation Generator Loss')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(d_loss, label='d_loss')\n",
    "plt.plot(val_d_loss, label='val_d_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0,2])\n",
    "plt.title('Training and Validation Discriminator Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(psnr, label='psnr')\n",
    "plt.plot(val_psnr, label='val_psnr')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Metric')\n",
    "plt.ylim([20,30])\n",
    "plt.title('Training and Validation Metric')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "\n",
    "plt.subplot(2,2, 4)\n",
    "plt.plot(ssim, label='ssim')\n",
    "plt.plot(val_ssim, label='val_ssim')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Metric')\n",
    "plt.ylim([0,1])\n",
    "plt.title('Training and Validation Metric')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHlu50mQMI9Q"
   },
   "source": [
    "## last epoch output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1675267107325,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "8ZnYSKgEe5Fz",
    "outputId": "bfe22a68-f350-40da-ea24-e254bfe4a318"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
    "display_image(history.epoch[-1]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBcY8Z_lMDet"
   },
   "source": [
    "## gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kKgxKjPfFtI"
   },
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "filenames = glob.glob('image*.png')\n",
    "filenames = sorted(filenames)\n",
    "frames = []\n",
    "for i,filename in enumerate(filenames):\n",
    "  if i % 1 == 0:\n",
    "    image = imageio.imread(filename)\n",
    "    frames.append(image)\n",
    "imageio.mimsave(anim_file, frames, format='GIF', fps=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597,
     "output_embedded_package_id": "18TVbLPDo7l7ZNB3m0yhnMqfgGd8W7_H1"
    },
    "executionInfo": {
     "elapsed": 50768,
     "status": "ok",
     "timestamp": 1675267161002,
     "user": {
      "displayName": "Maciej Pająk",
      "userId": "16559642405043724633"
     },
     "user_tz": -60
    },
    "id": "t_E64LPcfG-k",
    "outputId": "c1c0045a-165a-45bb-cb70-6b47e5f8403d"
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
